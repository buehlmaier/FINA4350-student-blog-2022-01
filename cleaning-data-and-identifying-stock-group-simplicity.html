<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="FINA4350 Students" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Progress Report, " />

<meta property="og:title" content="Cleaning Data and Identifying Stock (Group Simplicity) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/cleaning-data-and-identifying-stock-group-simplicity.html" />
<meta property="og:description" content="By Group &#34;Simplicity,&#34; written by Hang CHAN Cheuk Hang Author Introduction I&#39;m Hang and I&#39;m a final year student studying Economics and Finance at HKU, in charge of cleaning data (text) and identifying the stock mentioned within the text. Overall Objective and Workflow Using the data collected, we needed to …" />
<meta property="og:site_name" content="FINA4350 Student Blog" />
<meta property="og:article:author" content="FINA4350 Students" />
<meta property="og:article:published_time" content="2022-04-06T09:30:00+08:00" />
<meta name="twitter:title" content="Cleaning Data and Identifying Stock (Group Simplicity) ">
<meta name="twitter:description" content="By Group &#34;Simplicity,&#34; written by Hang CHAN Cheuk Hang Author Introduction I&#39;m Hang and I&#39;m a final year student studying Economics and Finance at HKU, in charge of cleaning data (text) and identifying the stock mentioned within the text. Overall Objective and Workflow Using the data collected, we needed to …">

        <title>Cleaning Data and Identifying Stock (Group Simplicity)  · FINA4350 Student Blog
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/"><span class=site-name>FINA4350 Student Blog</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2022-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/cleaning-data-and-identifying-stock-group-simplicity.html">
                Cleaning Data and Identifying Stock (Group Simplicity)
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>By Group "Simplicity," written by Hang CHAN Cheuk Hang</p>
<h2>Author Introduction</h2>
<p>I'm Hang and I'm a final year student studying Economics and Finance at HKU, in charge of cleaning data (text) and identifying the stock mentioned within the text.</p>
<h2>Overall Objective and Workflow</h2>
<p>Using the data collected, we needed to combine and clean the data, then identify the stock mentioned in the data. It is important to clean the data so that when sentiment analysis is conducted, it can be as accurate as possible. Then, output it as a CSV file for sentiment analysis. The steps are shown below:</p>
<ol>
<li>Read multiple Reddit CSV files as DataFrames and combine (concatenate) them</li>
<li>Clean the data within the Reddit DataFrame, specifically the Title, Content, and Comment columns</li>
<li>Read multiple Stock Ticker (NASDAQ, NYSE, AMEX) CSV files as DataFrames and combine (concatenate) them</li>
<li>Identify the stock mentioned in the data and confirm if it’s a real stock ticker</li>
<li>Output DataFrame as CSV for sentiment analysis</li>
</ol>
<p><strong><em>Libraries and Modules Used:</em></strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">emoji</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
</code></pre></div>

<p><strong><em>Overall Workflow Represented in main() Function:</em></strong></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">main</span><span class="p">():</span>

    <span class="c1"># Track start time</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="c1"># Path to access and output files</span>
    <span class="n">path</span> <span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;/Users/XFlazer/Documents/HKU/FBE/Finance/Natural Language Processing/Reddit Project&#39;</span>

    <span class="c1"># Read all reddit csv files as DataFrame</span>
    <span class="n">reddit_2018</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">sep</span> <span class="o">+</span> <span class="s1">&#39;Reddit WSB Data with most upvote comments 2018-09-01 to 2018-12-31.csv&#39;</span><span class="p">)</span>
    <span class="n">reddit_2019</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">sep</span> <span class="o">+</span> <span class="s1">&#39;Reddit WSB Data with most upvote comments 2019-01-01 to 2019-12-31.csv&#39;</span><span class="p">)</span>
    <span class="n">reddit_2020</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">sep</span> <span class="o">+</span> <span class="s1">&#39;Reddit WSB Data with most upvote comments 2020-01-01 to 2020-12-31.csv&#39;</span><span class="p">)</span>
    <span class="n">reddit_2021</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">sep</span> <span class="o">+</span> <span class="s1">&#39;Reddit WSB Data with most upvote comments 2021-01-01 to 2021-12-31.csv&#39;</span><span class="p">)</span>

    <span class="c1"># Make a copy to not affect original DataFrame</span>
    <span class="n">r_18</span> <span class="o">=</span> <span class="n">reddit_2018</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">r_19</span> <span class="o">=</span> <span class="n">reddit_2019</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">r_20</span> <span class="o">=</span> <span class="n">reddit_2020</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">r_21</span> <span class="o">=</span> <span class="n">reddit_2021</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="c1"># Place them into a list to combine them</span>
    <span class="n">r_lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">r_18</span><span class="p">,</span> <span class="n">r_19</span><span class="p">,</span> <span class="n">r_20</span><span class="p">,</span> <span class="n">r_21</span><span class="p">]</span>

    <span class="c1"># Combine all reddit DataFrames</span>
    <span class="n">reddit_df</span> <span class="o">=</span> <span class="n">combineDF</span><span class="p">(</span><span class="n">r_lst</span><span class="p">)</span>

    <span class="c1"># Clean the data</span>
    <span class="n">reddit_df</span> <span class="o">=</span> <span class="n">cleanData</span><span class="p">(</span><span class="n">reddit_df</span><span class="p">)</span>

    <span class="c1"># Read all stock ticker csv files as DataFrames</span>
    <span class="n">nasdaq_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">sep</span> <span class="o">+</span> <span class="s1">&#39;Nasdaq.csv&#39;</span><span class="p">)</span>
    <span class="n">nyse_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">sep</span> <span class="o">+</span> <span class="s1">&#39;Nyse.csv&#39;</span><span class="p">)</span>
    <span class="n">amex_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">sep</span> <span class="o">+</span> <span class="s1">&#39;Amex.csv&#39;</span><span class="p">)</span>

    <span class="c1"># Place them into a list to combine them</span>
    <span class="n">tickers_lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">nasdaq_df</span><span class="p">,</span> <span class="n">nyse_df</span><span class="p">,</span> <span class="n">amex_df</span><span class="p">]</span>

    <span class="c1"># Combine all stock ticker DataFrames</span>
    <span class="n">tickers_df</span> <span class="o">=</span> <span class="n">combineDF</span><span class="p">(</span><span class="n">tickers_lst</span><span class="p">)</span>

    <span class="c1"># Match the stock mentioned in text to a real stock ticker</span>
    <span class="n">reddit_df</span> <span class="o">=</span> <span class="n">stockMatch</span><span class="p">(</span><span class="n">reddit_df</span><span class="p">,</span> <span class="n">tickers_df</span><span class="p">)</span>

    <span class="c1"># Output file as csv for further analysis</span>
    <span class="n">reddit_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="n">os</span><span class="o">.</span><span class="n">sep</span> 
                          <span class="o">+</span> <span class="s1">&#39;reddit_with_ticker.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

    <span class="c1"># Prints out how long the program took in seconds</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The time it took to run the program:&#39;</span><span class="p">,</span> 
           <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span><span class="p">,</span> <span class="s1">&#39;seconds&#39;</span><span class="p">)</span>

<span class="c1"># Calls main program</span>
<span class="n">main</span><span class="p">()</span>
</code></pre></div>

<h2>Combine Reddit CSV Files into One DataFrame</h2>
<p>At first, I was  unsure whether or not to combine all the Reddit CSV files and then clean, or clean them individually first, and then combine. However, I decided to combine them first because it would mean all the data was within one DataFrame instead of multiple ones, making it cleaner and easier to work with even if it may take longer.</p>
<p><strong><em>Function to Combine (Concatenate) CSV Files</em></strong></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">combineDF</span><span class="p">(</span><span class="n">df_lst</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function concatenate all the DataFrames, returns a DataFrame</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Concatenate all the DataFrames and automatically reset index</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">df_lst</span><span class="p">,</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Returns df for cleaning</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div>

<h2>Cleaning Data</h2>
<p>Cleaning data in our case means to:</p>
<ol>
<li>Remove any row where the Title, Content, or Comment is identified as deleted, removed, or deleted by user</li>
<li>Remove any punctuation besides ‘!’, links, line spaces, usernames or subreddits mentioned in the Title, Content, and Comment. We keep '!' because it affects the sentiment.</li>
</ol>
<p>To complete 1., I could easily just take the rows where the Title of the post was '[deleted by user]' instead of removing the rows. I made sure to reset the index and drop the old index column so that the DataFrame is cleaner. Then, I repeated this step for Content and Comment columns. However, the content and comment columns have a different identification method for a post that was removed or deleted, which is displayed as '[removed]' and '[deleted]', respectively. Thus, for the text in the Title, Content, and Comment columns, I only took the valid ones.</p>
<p><strong><em>Function to Clean Data: Taking Non-Deleted Posts</em></strong></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">cleanData</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function cleans the DataFrame. It removes deleted posts, special</span>
<span class="sd">    words, and any confusing punctuation that may be referring to another</span>
<span class="sd">    user</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Takes rows where title is NOT deleted by user</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;[deleted by user]&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Takes rows where content is NOT removed or deleted</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;[removed]&#39;</span><span class="p">)</span> 
          <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;[deleted]&#39;</span><span class="p">)]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Takes rows where comment is NOT removed or deleted</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
            <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;comment_content&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;[removed]&#39;</span><span class="p">)</span> 
            <span class="o">&amp;</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;comment_content&#39;</span><span class="p">]</span> <span class="o">!=</span> <span class="s1">&#39;[deleted]&#39;</span><span class="p">)</span>
            <span class="p">]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</code></pre></div>

<p>Additionally, I had to keep the emojis and used the emoji module to create a list of emojis. Then, I joined them as a string with a ‘|’ delimiter as this signifies <em>or</em> during string manipulation. After, I considered using re.sub() and mapping it (.map()) to each of the three columns but I discovered a faster method. </p>
<p>I found a faster way by directly using df.Column.replace, which uses Series operation which should be faster than using .map(). To remove everything else besides the data we wanted to keep, I did the inverse of the usual Series.replace(). Everything within the brackets ‘[^ ]’ would be protected, and anything outside specifically mentioned will be replaced with an empty string. I learned that we could also add specific strings to be protected if it’s delimited by a ‘|’, hence the earlier joining of emojis to protect them. For the characters that would be deleted, it would only delete that specific character, but I learned that we needed to add the ‘\S+’ to indicate that any non-space character followed by it will also be replaced.</p>
<p>Finally, I would combine all the text within the three columns into one column. This will be needed to identify which stock is being discussed in the text. However, since we are taking the first stock mentioned, I decided to combine them in the order of Title, Content, Comment, as I assumed that the stock being discussed will be mentioned in the Title first. If not, it should be in the Content followed by the Comment. </p>
<p><strong><em>Function to Clean Data Continued: Keeping Only Words and Emojis (and '!')</em></strong></p>
<div class="highlight"><pre><span></span><code>    <span class="c1"># Use emoji module to create emoji list to keep emojis</span>
    <span class="n">emoji_lst</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">emoji</span><span class="o">.</span><span class="n">UNICODE_EMOJI</span><span class="p">[</span><span class="s1">&#39;en&#39;</span><span class="p">]]</span>

    <span class="c1"># Create a text of emojis so that it will not be filtered out when </span>
    <span class="c1"># cleaning</span>
    <span class="n">emojis</span> <span class="o">=</span> <span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">emoji_lst</span><span class="p">)</span>

    <span class="c1"># Remove punctuations (except &#39;!&#39;), links, line space, usernames </span>
    <span class="c1"># or subreddits from title</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
    <span class="sa">r</span><span class="s1">&#39;[^\w\s\!\</span><span class="si">{emojis}</span><span class="s1">]|http\S+|\n|u/\S+|r/\S+&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">emojis</span> <span class="o">=</span> <span class="n">emojis</span><span class="p">),</span>
     <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">regex</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Remove punctuations (except &#39;!&#39;), links, line space, usernames </span>
    <span class="c1"># or subreddits from content</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
    <span class="sa">r</span><span class="s1">&#39;[^\w\s\!\</span><span class="si">{emojis}</span><span class="s1">]|http\S+|\n|u/\S+|r/\S+&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">emojis</span> <span class="o">=</span> <span class="n">emojis</span><span class="p">),</span>
     <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">regex</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Remove punctuations (except &#39;!&#39;), links, line space, usernames </span>
    <span class="c1"># or subreddits from comment</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;comment_content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;comment_content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span>
    <span class="sa">r</span><span class="s1">&#39;[^\w\s\!\</span><span class="si">{emojis}</span><span class="s1">]|http\S+|\n|u/\S+|r/\S+&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">emojis</span> <span class="o">=</span> <span class="n">emojis</span><span class="p">),</span>
     <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">regex</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Combines all content into 1 cell for future use</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;all_content&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span>
                          <span class="p">[</span><span class="s1">&#39;title&#39;</span><span class="p">,</span> <span class="s1">&#39;content&#39;</span><span class="p">,</span> <span class="s1">&#39;comment_content&#39;</span><span class="p">]</span>
                          <span class="p">]</span><span class="o">.</span><span class="n">fillna</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">agg</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Returns the cleaned df for stock matching</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div>

<h2>Combine Stock Ticker CSV Files into One DataFrame</h2>
<p>I read all the Stock CSV files and combined them into a single DataFrame to make it easier to access all the stock tickers. The reason is the same as combining multiple Reddit CSV files. </p>
<h2>Stock Matching: Overall</h2>
<p>To match the stock mentioned in the text:</p>
<ol>
<li>Ignore some characters/words such as “I” or “ETF” so that it will not be confused with actual stock tickers</li>
<li>Match the first stock ticker mentioned in the text to a list of stock tickers from the Stock CSV DataFrame</li>
<li>Create a new column with the stock ticker identified and remove those without a stock ticker identified</li>
</ol>
<p><strong><em>Function to Match Stock</em></strong></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">stockMatch</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">t_df</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function attempts to recognize the stock mentioned in the title,</span>
<span class="sd">    comment, or comment post. Each word will be compared to a list of stock</span>
<span class="sd">    tickers. If there is no match, the row will not be included in the </span>
<span class="sd">    new DataFrame.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># Create a new column called &quot;removed_words&quot; to show the text after all</span>
    <span class="c1"># necessary words (ignored_words) are removed</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;removed_words&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;all_content&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">ignoreWords</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

    <span class="c1"># Create a new column called &quot;ticker&quot; to place the ticker identified</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;ticker&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;removed_words&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> 
                                           <span class="n">stockSearch</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(),</span> <span class="n">t_df</span><span class="p">))</span>

    <span class="c1"># Only takes rows where a stock ticker has been identified</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;ticker&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">notna</span><span class="p">()]</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Returns the DataFrame to main to be outputted as csv</span>
    <span class="k">return</span> <span class="n">df</span>
</code></pre></div>

<p>Initially, I used a nested loop to loop through the whole DataFrame and loop the text and match each word individually to a ticker in a list of stock tickers (while ignoring words that could be confused as stocks). However, that took way too long. Thus, I decided to create a new column where only the valid words would remain, meaning I had removed all the words that would be ignored. However, using a regular for loop still took quite a long time. </p>
<p>I initially re-used Series operation, i.e. df.Column.replace, creating a list of words to ignore, joining them with a ‘|’ delimiter, thus matching and replacing them with an empty string, effectively removing them. Strangely, it took too long for the program to run so I decided to pursue another method.</p>
<h2>Stock Matching: Ignore Words</h2>
<p>I created a new function called ignoreWords(text) and mapped the column with all the text to it. In that function, I created a set of words to ignore and tried to remove them if it matches the whole word, using re.sub() once again.</p>
<p>However, it just took too long, so I used a for loop to loop through each word (substring) within the text instead. Interestingly, although it still took a while, it was faster than using re.sub(). Then, I realized that we could also simply remove any substring that have a greater length than 5 (length of stock tickers &lt; 5), not lower or uppercase, e.g. “Last, To”, or any lowercase words. I considered using list comprehension but due to the number of rules, I decided against it in favor of readability. This sped up the program considerably. With the remaining text which are all uppercase words, I tried to match any word(s) to a stock ticker.</p>
<p><strong><em>Function to Ignore Words</em></strong></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">ignoreWords</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This functions takes in the text and removes certain words for stock</span>
<span class="sd">    search afterwards, returning the whole text after editing</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Words to ignore consisting of abbreviations redditors often use and other</span>
    <span class="c1"># common abbreviations</span>
    <span class="n">ignore_words</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;JAN&#39;</span><span class="p">,</span> <span class="s1">&#39;FEB&#39;</span><span class="p">,</span> <span class="s1">&#39;MAR&#39;</span><span class="p">,</span> <span class="s1">&#39;APR&#39;</span><span class="p">,</span> <span class="s1">&#39;MAY&#39;</span><span class="p">,</span> <span class="s1">&#39;JUN&#39;</span><span class="p">,</span> <span class="s1">&#39;JUL&#39;</span><span class="p">,</span> <span class="s1">&#39;AUG&#39;</span><span class="p">,</span> <span class="s1">&#39;SEP&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;OCT&#39;</span><span class="p">,</span> <span class="s1">&#39;NOV&#39;</span><span class="p">,</span> <span class="s1">&#39;DEC&#39;</span><span class="p">,</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="s1">&#39;I&#39;</span><span class="p">,</span> <span class="s1">&#39;U&#39;</span><span class="p">,</span> <span class="s1">&#39;ELON&#39;</span><span class="p">,</span> <span class="s1">&#39;MUSK&#39;</span><span class="p">,</span> <span class="s1">&#39;ETF&#39;</span><span class="p">,</span> <span class="s1">&#39;DFV&#39;</span><span class="p">,</span>
        <span class="s1">&#39;CATHIE&#39;</span><span class="p">,</span> <span class="s1">&#39;WOODS&#39;</span><span class="p">,</span> <span class="s1">&#39;TOS&#39;</span><span class="p">,</span> <span class="s1">&#39;ROPE&#39;</span><span class="p">,</span> <span class="s1">&#39;YOLO&#39;</span><span class="p">,</span> <span class="s1">&#39;CEO&#39;</span><span class="p">,</span> <span class="s1">&#39;CTO&#39;</span><span class="p">,</span> <span class="s1">&#39;CFO&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;COO&#39;</span><span class="p">,</span> <span class="s1">&#39;DD&#39;</span><span class="p">,</span> <span class="s1">&#39;IT&#39;</span><span class="p">,</span> <span class="s1">&#39;ATH&#39;</span><span class="p">,</span> <span class="s1">&#39;POS&#39;</span><span class="p">,</span>  <span class="s1">&#39;IMO&#39;</span><span class="p">,</span> <span class="s1">&#39;RED&#39;</span><span class="p">,</span> <span class="s1">&#39;KMS&#39;</span><span class="p">,</span> <span class="s1">&#39;KYS&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;GREEN&#39;</span><span class="p">,</span> <span class="s1">&#39;TLDR&#39;</span><span class="p">,</span> <span class="s1">&#39;LMAO&#39;</span><span class="p">,</span> <span class="s1">&#39;LOL&#39;</span><span class="p">,</span> <span class="s1">&#39;CUNT&#39;</span><span class="p">,</span> <span class="s1">&#39;SUBS&#39;</span><span class="p">,</span> <span class="s1">&#39;USD&#39;</span><span class="p">,</span> <span class="s1">&#39;CPU&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;AT&#39;</span><span class="p">,</span> <span class="s1">&#39;GG&#39;</span><span class="p">,</span> <span class="s1">&#39;AH&#39;</span><span class="p">,</span> <span class="s1">&#39;AM&#39;</span><span class="p">,</span> <span class="s1">&#39;PM&#39;</span><span class="p">,</span> <span class="s1">&#39;TICK&#39;</span><span class="p">,</span> <span class="s1">&#39;IS&#39;</span><span class="p">,</span> <span class="s1">&#39;EZ&#39;</span><span class="p">,</span> <span class="s1">&#39;RAW&#39;</span><span class="p">,</span> <span class="s1">&#39;ROFL&#39;</span><span class="p">,</span>
        <span class="s1">&#39;FOMO&#39;</span><span class="p">,</span> <span class="s1">&#39;FBI&#39;</span><span class="p">,</span> <span class="s1">&#39;SEC&#39;</span><span class="p">,</span> <span class="s1">&#39;GOD&#39;</span><span class="p">,</span><span class="s1">&#39;CIA&#39;</span><span class="p">,</span> <span class="s1">&#39;LONG&#39;</span><span class="p">,</span> <span class="s1">&#39;SHORT&#39;</span><span class="p">,</span> <span class="s1">&#39;ATM&#39;</span><span class="p">,</span> <span class="s1">&#39;OTM&#39;</span><span class="p">,</span>
        <span class="s1">&#39;ITM&#39;</span><span class="p">,</span> <span class="s1">&#39;TYS&#39;</span><span class="p">,</span> <span class="s1">&#39;IIRC&#39;</span><span class="p">,</span> <span class="s1">&#39;IIUC&#39;</span><span class="p">,</span> <span class="s1">&#39;PDT&#39;</span><span class="p">,</span> <span class="s1">&#39;TOS&#39;</span><span class="p">,</span> <span class="s1">&#39;TYS&#39;</span><span class="p">,</span> <span class="s1">&#39;OPEN&#39;</span><span class="p">,</span> <span class="s1">&#39;IRS&#39;</span><span class="p">,</span>
        <span class="s1">&#39;ALL&#39;</span><span class="p">,</span> <span class="s1">&#39;OK&#39;</span><span class="p">,</span> <span class="s1">&#39;BTFD&#39;</span><span class="p">,</span> <span class="s1">&#39;US&#39;</span><span class="p">,</span> <span class="s1">&#39;USA&#39;</span><span class="p">,</span> <span class="s1">&#39;GDP&#39;</span><span class="p">,</span> <span class="s1">&#39;FD&#39;</span><span class="p">,</span> <span class="s1">&#39;TL&#39;</span><span class="p">,</span> <span class="s1">&#39;OP&#39;</span><span class="p">,</span> <span class="s1">&#39;PS&#39;</span><span class="p">,</span>
        <span class="s1">&#39;WTF&#39;</span><span class="p">,</span> <span class="s1">&#39;FOMO&#39;</span><span class="p">,</span> <span class="s1">&#39;CALL&#39;</span><span class="p">,</span> <span class="s1">&#39;PUT&#39;</span><span class="p">,</span> <span class="s1">&#39;BE&#39;</span><span class="p">,</span> <span class="s1">&#39;PR&#39;</span><span class="p">,</span> <span class="s1">&#39;GUH&#39;</span><span class="p">,</span> <span class="s1">&#39;JPOW&#39;</span><span class="p">,</span> <span class="s1">&#39;BULL&#39;</span><span class="p">,</span>
        <span class="s1">&#39;BEAR&#39;</span><span class="p">,</span> <span class="s1">&#39;BUY&#39;</span><span class="p">,</span> <span class="s1">&#39;SELL&#39;</span><span class="p">,</span> <span class="s1">&#39;HE&#39;</span><span class="p">,</span> <span class="s1">&#39;ONE&#39;</span><span class="p">,</span> <span class="s1">&#39;OF&#39;</span><span class="p">,</span> <span class="s1">&#39;SHE&#39;</span><span class="p">,</span> <span class="s1">&#39;HODL&#39;</span><span class="p">,</span> <span class="s1">&#39;FINRA&#39;</span><span class="p">,</span>
        <span class="s1">&#39;WSB&#39;</span><span class="p">,</span> <span class="s1">&#39;MODS&#39;</span><span class="p">,</span> <span class="s1">&#39;MOD&#39;</span><span class="p">,</span> <span class="s1">&#39;EPS&#39;</span><span class="p">,</span> <span class="s1">&#39;IRA&#39;</span><span class="p">,</span> <span class="s1">&#39;ROTH&#39;</span><span class="p">,</span> <span class="s1">&#39;BS&#39;</span><span class="p">,</span> <span class="s1">&#39;RIP&#39;</span><span class="p">,</span> <span class="s1">&#39;OMG&#39;</span><span class="p">,</span> 
        <span class="s1">&#39;IM&#39;</span><span class="p">,</span> <span class="s1">&#39;YOU&#39;</span><span class="p">,</span> <span class="s1">&#39;DOW&#39;</span><span class="p">,</span> <span class="s1">&#39;ARE&#39;</span><span class="p">,</span> <span class="s1">&#39;FREE&#39;</span><span class="p">,</span> <span class="s1">&#39;MONEY&#39;</span>
        <span class="p">}</span>

    <span class="c1"># Split the text into a list of words</span>
    <span class="n">text_lst</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

    <span class="c1"># Loop through the list of words in text</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()):</span>

        <span class="c1"># Conditions in order to remove words: </span>
        <span class="c1"># Greater than 5 (length of stock ticker)</span>
        <span class="c1"># Word in ignore_words set</span>
        <span class="c1"># Not lower or uppercase words (e.g. Last) and not lowercase words</span>
        <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">5</span> 
            <span class="ow">or</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">ignore_words</span> 
            <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="n">word</span><span class="o">.</span><span class="n">isupper</span><span class="p">()</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">word</span><span class="o">.</span><span class="n">islower</span><span class="p">())</span> 
            <span class="ow">or</span> <span class="n">word</span><span class="o">.</span><span class="n">islower</span><span class="p">()):</span>
            <span class="n">text_lst</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>

    <span class="c1"># Returns a string after joining the list of words in text</span>
    <span class="k">return</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">text_lst</span><span class="p">)</span>
</code></pre></div>

<h2>Stock Searching</h2>
<p>Following my previous method, I also created a new function called stockSearch(text_lst, t_df). If there is no text, it would return NaN and if there are word(s), then it would compare it to a list of stock tickers. Since we only want the first stock mentioned, I used the break option even though it might not be elegant. The remaining text (after ignoreWords(text)) was mapped to this function.</p>
<p><strong><em>Function to Search for Stock Tickers</em></strong></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">stockSearch</span><span class="p">(</span><span class="n">text_lst</span><span class="p">,</span> <span class="n">t_df</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    This function searches for the stock ticker to match with the text list</span>
<span class="sd">    given. It then returns the FIRST stock identified.</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># Convert the stock ticker Series into a list</span>
    <span class="n">tickers_lst</span> <span class="o">=</span> <span class="p">(</span><span class="n">t_df</span><span class="p">[</span><span class="s1">&#39;Symbol&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_list</span><span class="p">())</span>

    <span class="c1"># If there is no text, return NaN</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">text_lst</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>

    <span class="c1"># Else, try to find the stock ticker</span>
    <span class="k">else</span><span class="p">:</span>

        <span class="c1"># For loop to loop through words in a text list</span>
        <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text_lst</span><span class="p">:</span>

            <span class="c1"># If the word matches the one in tickers list, returns the word</span>
            <span class="c1"># and breaks since only taking FIRST instance</span>
            <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">tickers_lst</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">word</span>
                <span class="k">break</span>
</code></pre></div>

<p>Once the stockSearch function was finished, I only took rows where a stock ticker has been identified and reset the index.</p>
<h2>Major Difficulties in Stock Matching</h2>
<p>While the code seemed relatively simple, it took me a long time to arrive there. After all, I was convinced that using a for loop for anything would take too long. Thus, I first tried to use <a href="https://stackoverflow.com/questions/54135085/create-new-column-based-on-string">np.select()</a> . Although I tested it for a single row and it found the matching stock ticker, it was too slow when applied to the whole DataFrame. </p>
<p><em>Too Slow: np.select()</em></p>
<div class="highlight"><pre><span></span><code><span class="n">conditions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;removed_words&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">,</span> 
                      <span class="nb">list</span><span class="p">(</span><span class="n">tickers_df</span><span class="o">.</span><span class="n">Symbol</span><span class="p">)))</span>

<span class="n">reddit_df</span><span class="p">[</span><span class="s1">&#39;tickers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">conditions</span><span class="p">,</span> 
                                 <span class="nb">list</span><span class="p">(</span><span class="n">tickers_df</span><span class="o">.</span><span class="n">Symbol</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
</code></pre></div>

<p>Next, I tried to use re.search() to find the index of the stock ticker matched, then <a href="https://stackoverflow.com/questions/17972938/check-if-a-string-in-a-pandas-dataframe-column-is-in-a-list-of-strings">use .start() and .end()</a> to return the word. However, when I tested it, I found that it would not match the whole ticker, but just the initial letters found which may correlate to a stock. For example, instead of returning SPY, it returns SP.</p>
<p><em>Did Not Return Correct Stock Ticker: re.search() and Function</em></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">pattern_searcher</span><span class="p">(</span><span class="n">search_str</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">search_list</span><span class="p">:</span><span class="nb">str</span><span class="p">):</span>
    <span class="n">search_obj</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">search_list</span><span class="p">,</span> <span class="n">search_str</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">search_obj</span> <span class="p">:</span>
        <span class="n">return_str</span> <span class="o">=</span> <span class="n">search_str</span><span class="p">[</span><span class="n">search_obj</span><span class="o">.</span><span class="n">start</span><span class="p">():</span> <span class="n">search_obj</span><span class="o">.</span><span class="n">end</span><span class="p">()]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">return_str</span> <span class="o">=</span> <span class="s1">&#39;NA&#39;</span>
    <span class="k">return</span> <span class="n">return_str</span>
</code></pre></div>

<p>Third, I tried to delete all stock tickers mentioned in the text and copy it to another piece of text using re.sub(). Then, I would find the unique value(s) between both texts and that would be the stock ticker! However, my first difficulty was finding a way to completely match word by word rather than by character. For example, the matching might return SP instead of SPY since SP is a real stock. Fortunately, there was a way to <a href="https://stackoverflow.com/questions/46898757/replace-a-word-in-a-string-if-it-is-in-a-list-of-words/46898770#46898770?newreg=e694e2cd6dd044f39c410ecc587db894">match the <strong>whole</strong> ticker</a> rather than some characters. After finding out how, I applied it to the column of text but it was still too slow.</p>
<p><em>Too Slow: re.sub()</em></p>
<div class="highlight"><pre><span></span><code><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s2">&quot;((?&lt;=\s)|(?&lt;=^))</span><span class="si">{}</span><span class="s2">((?=\s)|(?=$))&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">ticker_lst</span><span class="p">),</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
</code></pre></div>

<p>Therefore, I returned to using a for loop and .map().</p>
<h2>Output as CSV</h2>
<p>Once the DataFrame has been cleaned, and a stock has been identified, I outputted it as a CSV file so that sentiment analysis can be applied on the text.</p>
<p>An example of the CSV file:</p>
<p><img alt="Example of CSV File" src="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/images/group-Simplicity-040_Cleaned_Identified_Stock_CSV.png"></p>
<h2>Final Thoughts</h2>
<p>I found the data cleaning part relatively easier than identifying a stock. The main difficulty came from using conventional methods such as Series operations, which, for some reason, was slower than mapping a column to a function. Additionally, it was just more complex to identify a stock until I realized that the stock ticker mentioned must always be uppercase. However, I realize that my code can always be improved in terms of speed, perhaps using vector-based operations would make it more efficient.</p>
<p>To be sure, this was quite a challenging experience trying to find methods to identify the stock. I was stuck for more than a day doing this, surfing through <em>StackOverflow</em> for the best method. At the end, my bad practice of using for loops actually ended up solving the problem of speed and extracting the correct information for me! </p>
<p><em>Link to code can be found here:</em> <a href="https://github.com/u3555972/FINA4350-WSB-Sentiment-and-Stock-Returns/blob/3cb37224cd05c07975019de294cc0d04dd3e5cca/Cleaning%20Reddit%20Data%20and%20Identifying%20Stock.py">Cleaning Reddit Data and Identifying Stock</a></p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2022-04-06T09:30:00+08:00">Wed 06 April 2022</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/categories.html#progress-report-ref">Progress Report</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2022-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>