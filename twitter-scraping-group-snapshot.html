<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="FINA4350 Students" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Progress Report, " />

<meta property="og:title" content="Twitter Scraping (Group Snapshot) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/twitter-scraping-group-snapshot.html" />
<meta property="og:description" content="By Group &#34;Snapshot&#34;, written by Patrick van Ewijk Dear readers, this is the first blog post of our group, and its regarding the scraping of the twitter data. The blog describes the progress of the scraping, the problems I ran into and the corresponding solutions. As the question is whether …" />
<meta property="og:site_name" content="FINA4350 Student Blog" />
<meta property="og:article:author" content="FINA4350 Students" />
<meta property="og:article:published_time" content="2022-04-15T21:59:00+08:00" />
<meta name="twitter:title" content="Twitter Scraping (Group Snapshot) ">
<meta name="twitter:description" content="By Group &#34;Snapshot&#34;, written by Patrick van Ewijk Dear readers, this is the first blog post of our group, and its regarding the scraping of the twitter data. The blog describes the progress of the scraping, the problems I ran into and the corresponding solutions. As the question is whether …">

        <title>Twitter Scraping (Group Snapshot)  · FINA4350 Student Blog
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/"><span class=site-name>FINA4350 Student Blog</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2022-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/twitter-scraping-group-snapshot.html">
                Twitter Scraping (Group Snapshot)
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>By Group "Snapshot", written by Patrick van Ewijk</p>
<p>Dear readers, this is the first blog post of our group, and its regarding the scraping of the twitter data. 
The blog describes the progress of the scraping, the problems I ran into and the corresponding solutions.
As the question is whether the volatility of the bitcoin data can be predicted using the sentiment on twitter and reddit, historical data is of interest. Hence, for the twitter part we used the <em>snscrape</em> package. Further, we need <em>timedelta</em> (and later on <em>timezone</em>) from <em>datetime</em></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">snscrape.modules.twitter</span> <span class="k">as</span> <span class="nn">sntwitter</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">timedelta</span><span class="p">,</span> <span class="n">timezone</span>
</code></pre></div>

<h1>Our initial code</h1>
<p>We wrote a function which is shown below in order to scrape tweets from twitter. First, the function is presented. Hereafter, problems we ran into will be discussed.</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">ScrapData</span><span class="p">(</span><span class="n">MaxLimit</span><span class="p">,</span> <span class="n">Date_Start</span><span class="p">,</span> <span class="n">Date_End</span><span class="p">,</span> <span class="n">SearchQuery</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function that scrapes twitter data.</span>

<span class="sd">    Input:</span>
<span class="sd">    MaxLimit: Maximum number of tweets one wants to scrape during a day.</span>
<span class="sd">    Date_Start: Starting date. String in format: yyy-mm-dd</span>
<span class="sd">    Date_End: Ending date. String in format: yyy-mm-dd</span>
<span class="sd">    SearchQuery: What does one want to search on twitter?</span>
<span class="sd">    Optional Input:</span>
<span class="sd">    filename: Name of the file where one wants to write the output.</span>
<span class="sd">    Standard filename=None and the output is not stored.</span>
<span class="sd">    Output:</span>
<span class="sd">    dictionary with as keys the dates and</span>
<span class="sd">    as values a list of scraped tweets during the day.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">Dates</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">Date_Start</span><span class="p">,</span><span class="n">end</span><span class="o">=</span><span class="n">Date_End</span><span class="p">)</span>
    <span class="n">Dates_TweetsondayDict</span><span class="o">=</span><span class="p">{}</span>

    <span class="k">for</span> <span class="n">day</span> <span class="ow">in</span> <span class="n">Dates</span><span class="p">:</span>
        <span class="n">day_next</span><span class="o">=</span><span class="n">day</span><span class="o">+</span><span class="n">timedelta</span><span class="p">(</span><span class="n">days</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1">#running search</span>
        <span class="n">Query</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">SearchQuery</span><span class="si">}</span><span class="s2"> since:</span><span class="si">{</span><span class="n">day</span><span class="o">.</span><span class="n">date</span><span class="p">()</span><span class="si">}</span><span class="s2"> until:</span><span class="si">{</span><span class="n">day_next</span><span class="o">.</span><span class="n">date</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">tweets_list2</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">iteration</span><span class="p">,</span><span class="n">tweet</span> <span class="ow">in</span> \
            <span class="nb">enumerate</span><span class="p">(</span><span class="n">sntwitter</span><span class="o">.</span><span class="n">TwitterSearchScraper</span><span class="p">(</span><span class="n">Query</span><span class="p">)</span><span class="o">.</span><span class="n">get_items</span><span class="p">()):</span>
            <span class="k">if</span> <span class="n">iteration</span><span class="o">&gt;</span><span class="n">MaxLimit</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">tweets_list2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
        <span class="n">Dates_TweetsondayDict</span><span class="p">[</span><span class="n">day</span><span class="p">]</span><span class="o">=</span><span class="n">tweets_list2</span>
    <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">my_file</span><span class="p">:</span>
            <span class="n">pic</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">Dates_TweetsondayDict</span><span class="p">,</span> <span class="n">my_file</span><span class="p">,</span> <span class="n">pic</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>        
    <span class="k">return</span> <span class="n">Dates_TweetsondayDict</span>
</code></pre></div>

<p>For technical reasons, we made the decision to choose <code>MaxLimit=6000</code>. Scraping the data took 14 hours. For a long time I was satisfied with the output of the function. Everything seemed to work.
However, later on I found out that this function was not optimal.</p>
<h2>Problems</h2>
<p><strong>Problem 1: Not only tweets in English captured</strong></p>
<p>During the cleaning of the data, we found out that not only Tweets in English were collected; also tweets in Chinese and other languages were found. Of course, one could solve this by cleaning the data after the scraping. However, we preferred 'cleaner searching' over cleaning the searched data based on language afterwards.</p>
<p><strong>Problem 2: Collected tweets are not a random sample of all tweets during the day</strong> </p>
<p>It turned out that the function scraped only the last <code>MaxLimit</code> tweets of the day. In other words, in practice only tweets after 23.00 were captured. One could argue that the random sample assumption would be violated in this way. The information captured in tweets after 23.00 might be different from tweets during the rest of the day. Although this is not precisely bad, it is not what we wanted. In the optimal situation, we would like a sample of our tweets that represents the sentiment during the day as good as possible. </p>
<h1>Improving our code</h1>
<p>Solving <strong>Problem 1</strong> was relatively easy. By replacing <code>Query</code> by  </p>
<div class="highlight"><pre><span></span><code><span class="n">Query</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">SearchQuery</span><span class="si">}</span><span class="s2"> since_time:</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="s2"> until_time:</span><span class="si">{</span><span class="n">date_next</span><span class="si">}</span><span class="s2"> lang:en&quot;</span>
</code></pre></div>

<p>this problem is solved. Solving <strong>Problem 2</strong> was more difficult however.</p>
<p>Basically, I came up with two "solutions" for <strong>Problem 2</strong>.
* Increasing the <code>Maxlimit</code> such that Tweets over the whole day are captured.
* Searching hourly data, instead of daily data.</p>
<p>The first thought wouldn't be possible, because of technical constraints. The scraping would take , if one assumes a linear relation between execution time and #tweets, over 336 hours and the data files would be too large.</p>
<p>Hence, I implemented the second idea. However, when one searches on Twitter, one can only choose the day and not the time (see <a href="https://twitter.com/search-advanced">twitter.com</a>). That is, using the combination <code>since_time: 01-08-2021 00:00:00</code> and <code>until_time  01-08-2021 00:01:00</code> does not work.</p>
<p>Luckily, searching on the web usually leads to a solution. It turned out that one can use the <em>unix</em> time as an argument in <code>since_time</code> and <code>until_time</code>.</p>
<p>This resulted in the following function. </p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">ScrapData</span><span class="p">(</span><span class="n">MaxLimit</span><span class="p">,</span> <span class="n">Date_Start</span><span class="p">,</span> <span class="n">Date_End</span><span class="p">,</span> <span class="n">SearchQuery</span><span class="p">,</span> <span class="n">filename</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">Dates</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">date_range</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">Date_Start</span><span class="p">,</span><span class="n">end</span><span class="o">=</span><span class="n">Date_End</span><span class="p">,</span> <span class="n">freq</span><span class="o">=</span><span class="s1">&#39;h&#39;</span><span class="p">)</span>
    <span class="n">Dates_TweetsondayDict</span><span class="o">=</span><span class="p">{}</span>

    <span class="k">for</span> <span class="n">date</span> <span class="ow">in</span> <span class="n">Dates</span><span class="p">:</span>
        <span class="n">date_unix</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">date</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">tzinfo</span><span class="o">=</span><span class="n">timezone</span><span class="o">.</span><span class="n">utc</span><span class="p">)</span><span class="o">.</span><span class="n">timestamp</span><span class="p">())</span>
        <span class="n">date_unix_next</span><span class="o">=</span><span class="nb">int</span><span class="p">((</span><span class="n">date</span><span class="o">+</span><span class="n">timedelta</span><span class="p">(</span><span class="n">hours</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">tzinfo</span><span class="o">=</span><span class="n">timezone</span><span class="o">.</span><span class="n">utc</span><span class="p">)</span><span class="o">.</span><span class="n">timestamp</span><span class="p">())</span>
        <span class="c1">#running search</span>
        <span class="n">Query</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">SearchQuery</span><span class="si">}</span><span class="s2"> since_time:</span><span class="si">{</span><span class="n">date_unix</span><span class="si">}</span><span class="s2"> until_time:</span><span class="si">{</span><span class="n">date_unix_next</span><span class="si">}</span><span class="s2"> lang:en&quot;</span>
        <span class="n">tweets_list2</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">iteration</span><span class="p">,</span><span class="n">tweet</span> <span class="ow">in</span> \
            <span class="nb">enumerate</span><span class="p">(</span><span class="n">sntwitter</span><span class="o">.</span><span class="n">TwitterSearchScraper</span><span class="p">(</span><span class="n">Query</span><span class="p">)</span><span class="o">.</span><span class="n">get_items</span><span class="p">()):</span>
            <span class="k">if</span> <span class="n">iteration</span><span class="o">&gt;</span><span class="n">MaxLimit</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">tweets_list2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tweet</span><span class="p">)</span>
        <span class="n">Dates_TweetsondayDict</span><span class="p">[</span><span class="n">date_unix</span><span class="p">]</span><span class="o">=</span><span class="n">tweets_list2</span>
    <span class="k">if</span> <span class="n">filename</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">my_file</span><span class="p">:</span>
            <span class="n">pic</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">Dates_TweetsondayDict</span><span class="p">,</span> <span class="n">my_file</span><span class="p">,</span> <span class="n">pic</span><span class="o">.</span><span class="n">HIGHEST_PROTOCOL</span><span class="p">)</span>        
    <span class="k">return</span> <span class="n">Dates_TweetsondayDict</span>
</code></pre></div>

<p>Here we set <code>MaxLimit</code> 24 times as low as before. Further, we need the <em>timezone</em> to map our dates to the unix format.</p>
<h2>Additional benefit of solving this problem</h2>
<p>By selecting the tweets per hour instead of per day, we were multiplied the number of observations by a factor of 24. This is beneficial for our data analysis.</p>
<p>Thanks for reading. In case we indicate new problems, we will post a new blog post.</p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2022-04-15T21:59:00+08:00">Fri 15 April 2022</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/categories.html#progress-report-ref">Progress Report</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2022-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>