<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="FINA4350 Students" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Progress Report, " />

<meta property="og:title" content="Data Extraction, our Next Step! (Group Semantic Analysts) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/data-extraction-our-next-step-group-semantic-analysts.html" />
<meta property="og:description" content="By Group &#34;Semantic Analysts,&#34; written by Prateek Kher Introduction Don’t worry, if you are wondering this blog post will be as dull as the last, it would not. I will try to make this blog post as illustrative, interesting and interactive as possible! In this blog post, I will …" />
<meta property="og:site_name" content="FINA4350 Student Blog" />
<meta property="og:article:author" content="FINA4350 Students" />
<meta property="og:article:published_time" content="2022-04-02T08:00:00+08:00" />
<meta name="twitter:title" content="Data Extraction, our Next Step! (Group Semantic Analysts) ">
<meta name="twitter:description" content="By Group &#34;Semantic Analysts,&#34; written by Prateek Kher Introduction Don’t worry, if you are wondering this blog post will be as dull as the last, it would not. I will try to make this blog post as illustrative, interesting and interactive as possible! In this blog post, I will …">

        <title>Data Extraction, our Next Step! (Group Semantic Analysts)  · FINA4350 Student Blog
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/"><span class=site-name>FINA4350 Student Blog</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2022-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/data-extraction-our-next-step-group-semantic-analysts.html">
                Data Extraction, our Next Step!  (Group Semantic Analysts)
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>By Group "Semantic Analysts," written by Prateek Kher</p>
<h2>Introduction</h2>
<p>Don’t worry, if you are wondering this blog post will be as dull as the last, it would not. I will try to make this blog post as illustrative, interesting and interactive as possible! In this blog post, I will share how our group solved the problem of data extraction, and what will be the next steps! </p>
<h2>Objectives and How We Completed the Work</h2>
<p>Our group, wanted to approach this problem differently. There is no literature currently which talks about extracting data about fraudulent and non fraudulent companies using APIs, segregating them, training the model, and wait for the model to give us results. </p>
<p>Our first objective, was to figure out which data to use to conduct textual analysis. We then came across the Management Discussion and Analysis section data of 10-k filings with the SEC. We immediately knew our target! MD&amp;A section data provides a textual overview of company performance, in addition, a review of the objectives and goals for the following year is provided. Annual reports contain twice as much information in the language as they do in the financial figures. This section is critical in finding a company’s health! </p>
<p><strong><em> EDGAR, SEC and AAER </em></strong></p>
<p>The Securities and Exchange Commission (SEC) requires publicly traded companies to file a slew of documentation. The EDGAR database was designed by the Securities and Exchange Commission (SEC) to help preserve capital markets and make public company filings more accessible. It's a system that "performs automated functions," according to them. Companies and others who are required by law to file forms with the US government have their submissions gathered, evaluated, indexed, accepted, and forwarded. Each filing is kept as an index file in the EDGAR system, which includes the filer's name, a unique central index key, the date, and the directory of the EDGAR system. 
The picture below shows us a sample from the SEC EDGAR database form:</p>
<p><img alt="SEC EDGAR DATABASE" src="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/images/group-SemanticAnalyst-secdgartable.jpeg"></p>
<p>Our second objective was to create a database with known number of fraudulent, and non-fraudulent companies. To make such a database, we first have to know for sure, which companies have committed fraud in the past. This was the period which easily took our team the longest to do. We did not have relevant past literature review, to follow seemingly easy steps! We then thought of looking through the AAER reports, and then found, that UC Berkeley’s Center for Financial Reporting and Management (CFRM) releases a dataset annually which contains the AAER records of companies! These AAER records also contain the CIK (Central Index Key) of companies! We were enthralled! As we would use this was to extract the MD&amp;A section data from the 10-k files of companies. Table below shows a sample of AAER Dataset compiled by the CFRM. </p>
<p><img alt="AAER" src="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/images/group-SemanticAnalysts-AAER.jpeg"></p>
<p>We now have all of the information we need to complete the MD&amp;A column of our dataframe and classify instances as fraudulent or non-fraudulent. The CIK and the year connect both the pictures shown above. All of the overlapping cases in second picture have received an AAER, indicating that they are all fraudulent. We use the SEC-Query API's API to access the financial statement's HTML content using the CIK and the Year.  The remaining cases are chosen as non-fraudulent.  The Extractor API extracts any item from 10-Q and 10-K filings and returns it to you as cleaned and standardized text or HTML. An item is extracted as clear-text or ordinary HTML without the usage of an extraction algorithm. We then proceed to use the extractor algorithm to extract the raw data. </p>
<p>More interactive pictures and code shown below. </p>
<p>We first install the SEC-API</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="c1">#eac2066f382498aed48e5f03b594e7a5600120b542c08e03d59ca9ced2c6552c</span>
<span class="err">!</span> <span class="n">pip</span> <span class="n">install</span> <span class="o">--</span><span class="n">user</span> <span class="n">sec</span><span class="o">-</span><span class="n">api</span>
</code></pre></div>

<p>We download the AAER dataset, as shown in the code below, and we are good to go!</p>
<div class="highlight"><pre><span></span><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;AAER_firm_year.csv&quot;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s2">&quot;UNDERSTATEMENT&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;isFraud&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">df</span>
</code></pre></div>

<p>We use the queryAPI as shown below, coupled with the AAER dataset to solve our problem of getting the fraudulent and non-fraudulent companies. </p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sec_api</span> <span class="kn">import</span> <span class="n">QueryApi</span>
<span class="n">queryApi</span> <span class="o">=</span> <span class="n">QueryApi</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;eac2066f382498aed48e5f03b594e7a5600120b542c08e03d59ca9ced2c6552c&quot;</span><span class="p">)</span>
<span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df2</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
    <span class="n">query</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="p">{</span> <span class="s2">&quot;query_string&quot;</span><span class="p">:</span> <span class="p">{</span> 
          <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;cik:</span><span class="si">{</span><span class="n">row</span><span class="o">.</span><span class="n">CIK</span><span class="si">}</span><span class="s2"> AND filedAt:[</span><span class="si">{</span><span class="n">row</span><span class="o">.</span><span class="n">YEARA</span><span class="si">}</span><span class="s2">-01-01 TO </span><span class="si">{</span><span class="n">row</span><span class="o">.</span><span class="n">YEARA</span><span class="si">}</span><span class="s2">-12-31] AND formType:</span><span class="se">\&quot;</span><span class="s2">10-K</span><span class="se">\&quot;</span><span class="s2">&quot;</span> 
        <span class="p">}</span> <span class="p">},</span>
    <span class="p">}</span>
    <span class="n">filings</span> <span class="o">=</span> <span class="n">queryApi</span><span class="o">.</span><span class="n">get_filings</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
    <span class="k">if</span><span class="p">(</span><span class="n">filings</span><span class="p">[</span><span class="s1">&#39;total&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="mi">0</span><span class="p">):</span>
        <span class="n">row</span><span class="p">[</span><span class="s2">&quot;isFraud&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span> 
        <span class="n">row</span><span class="p">[</span><span class="s2">&quot;isFraud&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">count</span><span class="o">+=</span><span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">count</span><span class="p">,</span><span class="n">row</span><span class="o">.</span><span class="n">CIK</span><span class="p">)</span>
</code></pre></div>

<p>We go on to use the extractor API, which was extremely useful and proved to reduce our workload immensely. We currently just have the database which contains details whether companies are fraud or not, but our group did not want that, we wanted something more. Therefore, we used to extractor and query API to retrieve the MDA section data. </p>
<p>The code below was used to extract the MDA text:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sec_api</span> <span class="kn">import</span> <span class="n">ExtractorApi</span>
<span class="kn">from</span> <span class="nn">sec_api</span> <span class="kn">import</span> <span class="n">QueryApi</span>

<span class="n">queryApi</span> <span class="o">=</span> <span class="n">QueryApi</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;eac2066f382498aed48e5f03b594e7a5600120b542c08e03d59ca9ced2c6552c&quot;</span><span class="p">)</span>
<span class="n">query</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="p">{</span> <span class="s2">&quot;query_string&quot;</span><span class="p">:</span> <span class="p">{</span> 
      <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;cik:846909 AND formType:</span><span class="se">\&quot;</span><span class="s2">10-K</span><span class="se">\&quot;</span><span class="s2">&quot;</span> 
    <span class="p">}</span> <span class="p">},</span>
<span class="p">}</span>
<span class="n">filings</span> <span class="o">=</span> <span class="n">queryApi</span><span class="o">.</span><span class="n">get_filings</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">filings</span><span class="p">[</span><span class="s1">&#39;filings&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;linkToFilingDetails&#39;</span><span class="p">])</span>

<span class="n">extractorApi</span> <span class="o">=</span> <span class="n">ExtractorApi</span><span class="p">(</span><span class="s2">&quot;eac2066f382498aed48e5f03b594e7a5600120b542c08e03d59ca9ced2c6552c&quot;</span><span class="p">)</span>
<span class="n">queryApi</span> <span class="o">=</span> <span class="n">QueryApi</span><span class="p">(</span><span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;eac2066f382498aed48e5f03b594e7a5600120b542c08e03d59ca9ced2c6552c&quot;</span><span class="p">)</span>

<span class="c1">#6,22,32,52,91,93,47,29</span>

<span class="n">count</span><span class="o">=</span><span class="mi">0</span>
<span class="k">for</span> <span class="n">year</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2008</span><span class="p">,</span><span class="mi">2015</span><span class="p">):</span>
    <span class="n">query</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="p">{</span> <span class="s2">&quot;query_string&quot;</span><span class="p">:</span> <span class="p">{</span> 
          <span class="s2">&quot;query&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;filedAt:[</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">year</span><span class="p">)</span><span class="si">}</span><span class="s2">-01-01 TO </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">year</span><span class="p">)</span><span class="si">}</span><span class="s2">-12-31] AND formType:</span><span class="se">\&quot;</span><span class="s2">10-K</span><span class="se">\&quot;</span><span class="s2">&quot;</span> 
        <span class="p">}</span> <span class="p">},</span>

    <span class="p">}</span>
    <span class="n">filings</span> <span class="o">=</span> <span class="n">queryApi</span><span class="o">.</span><span class="n">get_filings</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">filings</span><span class="p">[</span><span class="s1">&#39;filings&#39;</span><span class="p">])):</span>
        <span class="k">if</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">filings</span><span class="p">[</span><span class="s1">&#39;filings&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;cik&#39;</span><span class="p">])</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">fraudpd</span><span class="o">.</span><span class="n">CIK</span><span class="o">.</span><span class="n">values</span><span class="p">):</span>
            <span class="k">if</span><span class="p">(</span><span class="s1">&#39;.htm&#39;</span> <span class="ow">in</span> <span class="n">filings</span><span class="p">[</span><span class="s1">&#39;filings&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;linkToFilingDetails&#39;</span><span class="p">]):</span>
                <span class="n">section_text</span> <span class="o">=</span> <span class="n">extractorApi</span><span class="o">.</span><span class="n">get_section</span><span class="p">(</span><span class="n">filings</span><span class="p">[</span><span class="s1">&#39;filings&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;linkToFilingDetails&#39;</span><span class="p">],</span> <span class="s2">&quot;7&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">)</span>
                <span class="k">if</span><span class="p">(</span><span class="n">section_text</span><span class="o">!=</span><span class="s2">&quot;undefined&quot;</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">section_text</span><span class="p">)</span><span class="o">&gt;</span><span class="mi">1000</span><span class="p">):</span>
                    <span class="n">count</span><span class="o">+=</span><span class="mi">1</span>
                    <span class="n">section_text</span> <span class="o">=</span> <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">section_text</span><span class="o">.</span><span class="n">split</span><span class="p">())</span>
                    <span class="n">entry</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;CIK&#39;</span><span class="p">:</span> <span class="nb">int</span><span class="p">(</span><span class="n">filings</span><span class="p">[</span><span class="s1">&#39;filings&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;cik&#39;</span><span class="p">]),</span> <span class="s1">&#39;YEARA&#39;</span><span class="p">:</span> <span class="n">filings</span><span class="p">[</span><span class="s1">&#39;filings&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">][</span><span class="s1">&#39;filedAt&#39;</span><span class="p">],</span> <span class="s1">&#39;isFraud&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span><span class="s1">&#39;MDA&#39;</span><span class="p">:</span><span class="n">section_text</span><span class="p">}</span>
                    <span class="n">fraudpd</span><span class="o">=</span> <span class="n">fraudpd</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entry</span><span class="p">,</span> <span class="n">ignore_index</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">count</span><span class="p">)</span>
</code></pre></div>

<p>Once we execute the code above, we can do some extra data cleaning. We can delete unneccesary columns, and our final dataframe looks like the picture shown below: </p>
<p><img alt="Final Dataframe" src="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/images/group-SemanticAnalysts-finaldataframe.jpeg"></p>
<h2>Learning Outcomes, both Qualitative and Quantitative!</h2>
<p>This part applies universally to anyone reading this blog post, or attempting to scrape data via SEC EDGAR database, and the AAER UC Berkeley database. We had to customise the data extraction techniques as per our use-case requirement, but what kept us going was the hustle to solve the problem. As we progressed forward, we started getting deeper and deeper into the question as to why we started in the first place? Going forward, we learnt that no matter what - be patient. For our team, this part took more than 1 month, to extract relevant data, and to sit down and understand how to edit it, and use the API keys to navigate through the data. Patience has been key in determining our success. Apart from patience, we definitely learnt how to use API keys properly, and extract data from them. This class has been immense in teaching me how to scrape data, both using web scraping technology directly from websites, as I did for my midterm project, but also through API keys. </p>
<p>What we could have done better? I believe our team has progressed decently, but our work distribution was not set correctly. Recommendation for all the team following the same things that we tried to do, do follow a set guideline when it comes to work, and stick to timelines. We could have also technically used the API keys before. We were trying to extract data manually using obsolete measures, which took up quite a lot of our time as well. </p>
<p>However, we aim to continue achieving our results through this mindset, as we know when we run our models, this will require immense amount of patience, labor, time and effort. I am personally looking forward to it, and I am willing to see what I can learn more in this journey. </p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2022-04-02T08:00:00+08:00">Sat 02 April 2022</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/categories.html#progress-report-ref">Progress Report</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2022-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>