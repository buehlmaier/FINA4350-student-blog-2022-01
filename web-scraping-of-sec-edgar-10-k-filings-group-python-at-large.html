<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="FINA4350 Students" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Progress Report, " />

<meta property="og:title" content="Web-scraping of SEC EDGAR 10-K filings (Group Python at Large) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/web-scraping-of-sec-edgar-10-k-filings-group-python-at-large.html" />
<meta property="og:description" content="By Group &#34;Python at Large&#34; The first step of our group project involves extracting the textual data from Item 7. Management&#39;s Discussion and Analysis, and Notes to consolidated financial in Item 8. Financial Statements and Supplementary Data of SEC 10-K file. According to SEC EDGAR, there is an Extractor API …" />
<meta property="og:site_name" content="FINA4350 Student Blog" />
<meta property="og:article:author" content="FINA4350 Students" />
<meta property="og:article:published_time" content="2022-04-10T00:00:00+08:00" />
<meta name="twitter:title" content="Web-scraping of SEC EDGAR 10-K filings (Group Python at Large) ">
<meta name="twitter:description" content="By Group &#34;Python at Large&#34; The first step of our group project involves extracting the textual data from Item 7. Management&#39;s Discussion and Analysis, and Notes to consolidated financial in Item 8. Financial Statements and Supplementary Data of SEC 10-K file. According to SEC EDGAR, there is an Extractor API …">

        <title>Web-scraping of SEC EDGAR 10-K filings (Group Python at Large)  · FINA4350 Student Blog
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/"><span class=site-name>FINA4350 Student Blog</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2022-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/web-scraping-of-sec-edgar-10-k-filings-group-python-at-large.html">
                Web-scraping of SEC EDGAR 10-K filings (Group Python at Large)
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>By Group "Python at Large"</p>
<p>The first step of our group project involves extracting the textual data from Item 7. Management's Discussion and Analysis, and Notes to consolidated financial in Item 8. Financial Statements and Supplementary Data of SEC 10-K file.  <br>
According to SEC EDGAR, there is an Extractor API that enables easy extraction of the sections needed from 10-K files.<br>
An example of the code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">sec_api</span> <span class="kn">import</span> <span class="n">ExtractorApi</span>
<span class="n">extractorApi</span> <span class="o">=</span> <span class="n">ExtractorApi</span><span class="p">(</span><span class="s2">&quot;API Key&quot;</span><span class="p">)</span> <span class="c1">#need to get the &#39;API Key&#39; from https://sec-api.io/</span>
<span class="c1"># the 10-K url of VEEVA SYSTEMS INC</span>
<span class="n">filing_url</span> <span class="o">=</span> <span class="s2">&quot;https://www.sec.gov/Archives/edgar/data/0001393052/000156459018007164/veev-10k_20180131.htm&quot;</span>
<span class="c1"># get the original text of Item 7</span>
<span class="n">section_text</span> <span class="o">=</span> <span class="n">extractorApi</span><span class="o">.</span><span class="n">get_section</span><span class="p">(</span><span class="n">filing_url</span><span class="p">,</span> <span class="s2">&quot;7&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">section_text</span><span class="p">)</span>
</code></pre></div>

<p>Although the API is a very handy tool, SEC only allows a limited number of extraction for each free API key. We then have to find other ways to download and extract the textual data needed.   <br>
To download the 10-K filings from SEC EDGAR, we made several different tryouts.</p>
<h3>Tryout 1: use 'request' package</h3>
<h4>Step 1: Download the quarterly index files using <a href="https://pypi.org/project/python-edgar/">edgar</a> package.</h4>
<p>The code we use for this step is as follows:  </p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_index_files</span><span class="p">(</span><span class="n">start_year</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="nb">str</span><span class="p">,</span>
                   <span class="n">store_path</span> <span class="o">=</span> <span class="nb">str</span><span class="p">,</span>
                   <span class="n">user</span> <span class="o">=</span> <span class="nb">str</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Download the crude index files from sec-edgar</span>
<span class="sd">    :param start_year: int, the starting year of indices that we want (2014 in our case)</span>
<span class="sd">    :param store_path: str, the path to store the crude index file</span>
<span class="sd">    :param user: str, username to download index file, usually company email (hku student could simply use the @connect.hku.hk email)</span>
<span class="sd">    :return: none, but index file will be downloaded and stored in store_path</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">ed</span><span class="o">.</span><span class="n">download_index</span><span class="p">(</span><span class="n">store_path</span><span class="p">,</span> <span class="n">start_year</span><span class="p">,</span> <span class="n">user</span><span class="p">,</span> <span class="n">skip_all_present_except_last</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># sample program to use the function</span>
<span class="n">get_index_files</span><span class="p">(</span><span class="n">start_year</span> <span class="o">=</span> <span class="mi">2016</span><span class="p">,</span> <span class="n">store_path</span> <span class="o">=</span> <span class="s1">&#39;./&#39;</span><span class="p">,</span> <span class="n">user</span> <span class="o">=</span> <span class="s1">&#39;YourUID@connect.hku.hk&#39;</span><span class="p">)</span>
</code></pre></div>

<h4>Step 2: Clean and merge all index files to get a complete list during the specified period</h4>
<p>The code we use for this step is as follows:  </p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">clean_index_files</span><span class="p">(</span><span class="n">start_year</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                      <span class="n">end_year</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
                      <span class="n">read_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Get the complete and clean index list from the crude index file</span>
<span class="sd">    :param start_year: int, starting year of 10K reports we want (2016 in our case)</span>
<span class="sd">    :param end_year: int, ending year of 10K reports we want (2020 in our case)</span>
<span class="sd">    :param read_path: str, the path to load the crude index file from (same as the store_path in Step 1)</span>
<span class="sd">    :return: DataFrame, the complete index file</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">start_year</span><span class="p">,</span><span class="n">end_year</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span> <span class="c1"># for each year&#39;s indices</span>
        <span class="c1"># load the indices of all quarters</span>
        <span class="n">q1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">read_path</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;-QTR1.tsv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;|&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">q2</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">read_path</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">+</span><span class="s1">&#39;-QTR2.tsv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;|&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">q3</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">read_path</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;-QTR3.tsv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;|&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">q4</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">read_path</span><span class="p">)</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;-QTR4.tsv&#39;</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;|&quot;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">q1</span><span class="p">,</span><span class="n">q2</span><span class="p">,</span><span class="n">q3</span><span class="p">,</span><span class="n">q4</span><span class="p">],</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">m</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;CIK&#39;</span><span class="p">,</span> <span class="s1">&#39;Comname&#39;</span><span class="p">,</span> <span class="s1">&#39;File_Type&#39;</span><span class="p">,</span> <span class="s1">&#39;File_Date&#39;</span><span class="p">,</span> <span class="s1">&#39;txt_path&#39;</span><span class="p">,</span> <span class="s1">&#39;html_path&#39;</span><span class="p">]</span>
        <span class="c1"># keep only 10K reports</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="p">[</span><span class="n">m</span><span class="p">[</span><span class="s1">&#39;File_Type&#39;</span><span class="p">]</span><span class="o">==</span><span class="s1">&#39;10-K&#39;</span><span class="p">]</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CIK&#39;</span><span class="p">,</span><span class="s1">&#39;File_Date&#39;</span><span class="p">])</span>
        <span class="n">m</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
        <span class="c1"># merge indices of all quarters in all years together to get the complete index list</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">indices</span><span class="p">,</span><span class="n">m</span><span class="p">],</span><span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># add the txt_name column for later use</span>
    <span class="n">indices</span><span class="p">[</span><span class="s1">&#39;txt_name&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="s1">&#39;txt_path&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">indices</span>

<span class="c1"># sample program to use the function</span>
<span class="n">indices</span> <span class="o">=</span> <span class="n">clean_index_files</span><span class="p">(</span><span class="n">start_year</span><span class="o">=</span><span class="mi">2016</span><span class="p">,</span><span class="n">end_year</span><span class="o">=</span><span class="mi">2020</span><span class="p">,</span><span class="n">read_path</span><span class="o">=</span><span class="s1">&#39;./&#39;</span><span class="p">)</span>
</code></pre></div>

<h4>Step 3: Download 10-K txt files according to the index file using requests</h4>
<p>The code we use for this step is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_10K_txt</span><span class="p">(</span><span class="n">txt_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                <span class="n">txt_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
                <span class="n">store_path</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">DATA_CRUDE</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Get raw 10K txt file and store it in specified directories</span>
<span class="sd">    :param txt_path: str, the txt path to download 10K from</span>
<span class="sd">    :param txt_name: str, the name of 10K txt file</span>
<span class="sd">    :param store_path: str, path to store crude 10K txt file</span>
<span class="sd">    :return: none, but 10K txt file will be stored in specified directories</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="c1"># get the desired 10K report by requests</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;https://www.sec.gov/Archives/&#39;</span> <span class="o">+</span> <span class="n">txt_path</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;User-Agent&#39;</span><span class="p">:</span> <span class="s1">&#39;Mozilla/5.0&#39;</span><span class="p">})</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">store_path</span><span class="p">):</span>
        <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">store_path</span><span class="p">)</span>

    <span class="c1"># store the 10K into specified path</span>
    <span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">store_path</span> <span class="o">+</span> <span class="n">txt_name</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
    <span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
<span class="c1"># sample program to use the function</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">[</span><span class="s1">&#39;CIK&#39;</span><span class="p">])):</span> <span class="c1"># download all the 10K reports listed in the cleaned index file</span>
    <span class="n">txt_path</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;txt_path&#39;</span><span class="p">]</span>
    <span class="n">txt_name</span> <span class="o">=</span> <span class="n">indices</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="s1">&#39;txt_name&#39;</span><span class="p">]</span>
    <span class="n">get_10K_txt</span><span class="p">(</span><span class="n">txt_path</span><span class="p">,</span><span class="n">txt_name</span><span class="p">)</span>
</code></pre></div>

<h4>Pros:</h4>
<ol>
<li>This is the most original way to scrape 10-K files on our own. Instead of relying on additional database for accessing the 10-K reports, we download them using 'requests' directly.</li>
<li>The 10-K reports downloaded are completely raw, so we could make any further conversion or calculation on our own.</li>
</ol>
<h4>Cons:</h4>
<ol>
<li>This is the most tedious way to obtain 10-K reports, it takes several steps to download them.</li>
<li>The index files are directly downloaded and stored in a specified directory rather than loaded as a variable in IDE.</li>
<li>The index files downloaded are quarterly, if we want to obtain 10-K across years, we need to merge quarterly files into yearly files.</li>
<li>The 10-K reports are raw, taking up a lot of memory space (around 160MB per 10 files). It also takes a lot of time to download them (around 13 seconds per 10 files).</li>
</ol>
<h3>Tryout 2: use 'secedgar' package</h3>
<p>We also find a handy package <a href="https://sec-edgar.github.io/sec-edgar/index.html">secedgar(version 0.4.0a2)</a> that can scrape all types of SEC filings.</p>
<p>The code we use is as follows:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># import date</span>
<span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">date</span>
<span class="c1"># import nest_asyncio to allow nested use</span>
<span class="kn">import</span> <span class="nn">nest_asyncio</span>
<span class="n">nest_asyncio</span><span class="o">.</span><span class="n">apply</span><span class="p">()</span>
<span class="c1"># import CompanyFilings, FilingType from secedgar for scraping filings from SEC EDGAR</span>
<span class="kn">from</span> <span class="nn">secedgar</span> <span class="kn">import</span> <span class="n">CompanyFilings</span><span class="p">,</span> <span class="n">FilingType</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="sd">class CompanyFilings() - Base class for receiving EDGAR filings.</span>
<span class="sd">:param cik_lookup: str/list of str, the ticker(s) of concerned firm(s)</span>
<span class="sd">:param filing_type: valid filing type enum,</span>
<span class="sd">      incorporated in the Union[secedgar.core.filing_types.FilingType],</span>
<span class="sd">      (in our case &#39;FILING_10K&#39;)</span>
<span class="sd">:param start_date: datetime.date, the starting date of files we need</span>
<span class="sd">:param end_date: datetime.date, the ending date of files we need</span>
<span class="sd">:param user_agent: str, username to download crude files,</span>
<span class="sd">      usually takes the form of &#39;yourname(company email)&#39;</span>
<span class="sd">      (hku student could simply use the @connect.hku.hk email)</span>
<span class="sd">&#39;&#39;&#39;</span>
<span class="n">cik_list</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;aapl&quot;</span><span class="p">,</span> <span class="s2">&quot;fb&quot;</span><span class="p">,</span> <span class="s2">&quot;msft&quot;</span><span class="p">]</span>
<span class="c1"># download filings of companies of interests in the cik_list</span>
<span class="n">my_filings</span> <span class="o">=</span> <span class="n">CompanyFilings</span><span class="p">(</span><span class="n">cik_lookup</span> <span class="o">=</span> <span class="n">cik_list</span><span class="p">,</span>
                          <span class="n">filing_type</span> <span class="o">=</span> <span class="n">FilingType</span><span class="o">.</span><span class="n">FILING_10K</span><span class="p">,</span>
                          <span class="n">start_date</span> <span class="o">=</span> <span class="n">date</span><span class="p">(</span><span class="mi">2016</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                          <span class="n">end_date</span> <span class="o">=</span> <span class="n">date</span><span class="p">(</span><span class="mi">2020</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">31</span><span class="p">),</span>
                          <span class="n">user_agent</span> <span class="o">=</span> <span class="s2">&quot;YourName(YourUID@connect.hku.hk)&quot;</span><span class="p">)</span>
<span class="c1"># save the downloaded files into a given path</span>
<span class="n">my_filings</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;./10-K&#39;</span><span class="p">)</span>
</code></pre></div>

<p>*<em>For demonstration purpose, we only include three companies in the</em> <code>cik_list</code>.</p>
<h4>Pros:</h4>
<ol>
<li>This is package is easier to use than 'request'. We can directly scrape filings given the time range and the list of tickers of the target companies.</li>
<li>The package enables a faster scraping speed (around 4 files per second)</li>
</ol>
<h4>Cons:</h4>
<ol>
<li>Same as using 'request', the raw text files can only be directly stored in a specified local directory rather than a variable in the IDE.</li>
<li>Same as using 'request', the raw 10-K reports take up too much memory storage.</li>
<li>It takes longer time to read through each file to clean and extract textual data.</li>
</ol>
<h3>Tryout 3: download from public data repository contributed by other researchers</h3>
<p>We then found a data repository with all cleaned raw 10-K files available from 1993 to 2021.
<a href="https://sraf.nd.edu/sec-edgar-data/">The Notre Dame Software Repository for Accounting and Finance (SRAF)</a>
is a website designed to provide a central repository for programs and data used in accounting and finance research, with a focus on textual analysis.</p>
<p>For our project, we ended up directly downloading cleaned data files and then extract the concerned sections. However, our previous tryouts act as valuable experience and could be transferrable to analyzing other types of SEC filings that are not directly available in the repository.</p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2022-04-10T00:00:00+08:00">Sun 10 April 2022</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/categories.html#progress-report-ref">Progress Report</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2022-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>