<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="FINA4350 Students" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content=", Progress Report, " />

<meta property="og:title" content="Tokenize and cleaning news data (Group Stonks) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/tokenize-and-cleaning-news-data-group-stonks.html" />
<meta property="og:description" content="By JIANG Zeyu and HUANG Yining of group Stonks Background Since machine cannot understand natural languages directly, a simple and general way to do that it to split sentence into words, and use index to substitute the words. In this way, we could generate a feature matrix which could be …" />
<meta property="og:site_name" content="FINA4350 Student Blog" />
<meta property="og:article:author" content="FINA4350 Students" />
<meta property="og:article:published_time" content="2022-04-12T11:12:00+08:00" />
<meta name="twitter:title" content="Tokenize and cleaning news data (Group Stonks) ">
<meta name="twitter:description" content="By JIANG Zeyu and HUANG Yining of group Stonks Background Since machine cannot understand natural languages directly, a simple and general way to do that it to split sentence into words, and use index to substitute the words. In this way, we could generate a feature matrix which could be …">

        <title>Tokenize and cleaning news data (Group Stonks)  · FINA4350 Student Blog
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/"><span class=site-name>FINA4350 Student Blog</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2022-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/tokenize-and-cleaning-news-data-group-stonks.html">
                Tokenize and cleaning news data (Group Stonks)
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>By JIANG Zeyu and HUANG Yining of group Stonks</p>
<h2>Background</h2>
<p>Since machine cannot understand natural languages directly, a simple and general way to do that it to split sentence into words, and use index to substitute the words. In this way, we could generate a feature matrix which could be used in our deep learning pipeline. However, there would be words that are not relavent and would affect the accuracy of result. There would also be words that represent same idea but of different forms. We have to deal with these problems.</p>
<p>Here, we want to present a simplified but standard pipeline to preprocess and tokenize any data, not just news.</p>
<h2>Pipline</h2>
<h3>1. Tokenize (Word Fragmentation)</h3>
<p>Tokenize might be the most simple step in the whole pipeline. It will only split one sentence into several words. For example:</p>
<div class="highlight"><pre><span></span><code><span class="c">Input: &quot;I am a student in HKU&quot;</span>
<span class="c">Output: [&quot;I&quot;, &quot;am&quot;, &quot;a&quot;, &quot;student&quot;, &quot;in&quot;, &quot;HKU&quot;]</span>
</code></pre></div>

<p>It seems simple, but it could be quite complex considering following example:</p>
<div class="highlight"><pre><span></span><code><span class="c">Input: &quot;Machine learning time-consuming&quot;</span>
<span class="err">Output?: [&quot;Machine&quot;, &quot;learning&quot;, &quot;is&quot;, &quot;time-consuming&quot;]</span>
</code></pre></div>

<p>You, as a human being, could clearly identify that <strong><em>Machine learning</em></strong> might be resolved as one token rather than two, or it may not match with <strong><em>Machine-learning</em></strong> in other sentences. However, after checked a few libraries, none of them have resolved this issue, therefore we have to put the pressure of identifying these terms to machine learning.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">nltk</span>

<span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="s2">&quot;Machine learning is time-consuming&quot;</span><span class="p">)</span>

<span class="o">&gt;&gt;</span> <span class="p">[</span><span class="s2">&quot;Machine&quot;</span><span class="p">,</span> <span class="s2">&quot;learning&quot;</span><span class="p">,</span> <span class="s2">&quot;is&quot;</span><span class="p">,</span> <span class="s2">&quot;time-consuming&quot;</span><span class="p">]</span>
</code></pre></div>

<p>However, these tokenizer would also make links or emojis into separated tokens, which is definitly what we want.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">nltk</span>

<span class="n">tweet</span> <span class="o">=</span> <span class="s2">&quot;RT @angelababy: love you baby! :D http://ah.love #168cm&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">tweet</span><span class="p">))</span>

<span class="o">&gt;&gt;</span> <span class="p">[</span><span class="s1">&#39;RT&#39;</span><span class="p">,</span> <span class="s1">&#39;@&#39;</span><span class="p">,</span> <span class="s1">&#39;angelababy&#39;</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="s1">&#39;love&#39;</span><span class="p">,</span> <span class="s1">&#39;you&#39;</span><span class="p">,</span> <span class="s1">&#39;baby&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="s1">&#39;http&#39;</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="s1">&#39;//ah.love&#39;</span><span class="p">,</span> <span class="s1">&#39;#&#39;</span><span class="p">,</span> <span class="s1">&#39;168cm&#39;</span><span class="p">]</span>
</code></pre></div>

<p>To resolve the issue, we define some regex expressions to deal with these special cases.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">re</span>

<span class="n">emojis</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    (?:</span>
<span class="s2">        [:=;]</span>
<span class="s2">        [oO\-]?</span>
<span class="s2">        [D\)\]\(\]/\\OpP]</span>
<span class="s2">    )&quot;&quot;&quot;</span>
<span class="n">regex</span> <span class="o">=</span> <span class="p">[</span>
    <span class="n">emojis</span><span class="p">,</span>
    <span class="sa">r</span><span class="s1">&#39;&lt;[^&gt;]+&gt;&#39;</span><span class="p">,</span> <span class="c1"># HTML Tags</span>
    <span class="sa">r</span><span class="s1">&#39;(?:@[\w_]+)&#39;</span><span class="p">,</span> <span class="c1"># Mention</span>
    <span class="sa">r</span><span class="s2">&quot;(?:\#+[\w_]+[\w\&#39;_\-]*[\w_]+)&quot;</span><span class="p">,</span> <span class="c1"># Hashtags</span>
    <span class="sa">r</span><span class="s1">&#39;http[s]?://(?:[a-z]|[0-9]|[$-_@.&amp;amp;+]|[!*\(\),]|(?:%[0-9a-f][0-9a-f]))+&#39;</span><span class="p">,</span> <span class="c1"># URLs</span>
    <span class="sa">r</span><span class="s1">&#39;(?:(?:\d+,?)+(?:\.?\d+)?)&#39;</span><span class="p">,</span> <span class="c1"># Number</span>
    <span class="sa">r</span><span class="s2">&quot;(?:[a-z][a-z&#39;\-_]+[a-z])&quot;</span><span class="p">,</span> <span class="c1"># -/`</span>
    <span class="sa">r</span><span class="s1">&#39;(?:[\w_]+)&#39;</span><span class="p">,</span>
    <span class="sa">r</span><span class="s1">&#39;(?:\S)&#39;</span>
<span class="p">]</span>
</code></pre></div>

<p>Also, we need to ignore cases when matching these regex expressions, after matching these expressions we could split them into tokens to satisfy our need.</p>
<div class="highlight"><pre><span></span><code><span class="n">tokens_re</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;(&#39;</span> <span class="o">+</span> <span class="s1">&#39;|&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">regex</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;)&#39;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">VERBOSE</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
<span class="n">emoticons_re</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;^&#39;</span> <span class="o">+</span> <span class="n">emojis</span> <span class="o">+</span> <span class="s1">&#39;$&#39;</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">VERBOSE</span> <span class="o">|</span> <span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokens_re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">preprocess</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">lowercase</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">lowercase</span><span class="p">:</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">if</span> <span class="n">emoticons_re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">else</span> <span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">tokens</span>
<span class="n">tweet</span> <span class="o">=</span> <span class="s2">&quot;RT @angelababy: love you baby! :D http://ah.love #168cm&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">preprocess</span><span class="p">(</span><span class="n">tweet</span><span class="p">))</span>

<span class="o">&gt;&gt;</span> <span class="p">[</span><span class="s1">&#39;RT&#39;</span><span class="p">,</span> <span class="s1">&#39;@angelababy&#39;</span><span class="p">,</span> <span class="s1">&#39;:&#39;</span><span class="p">,</span> <span class="s1">&#39;love&#39;</span><span class="p">,</span> <span class="s1">&#39;you&#39;</span><span class="p">,</span> <span class="s1">&#39;baby&#39;</span><span class="p">,</span> <span class="s1">&#39;!&#39;</span><span class="p">,</span> <span class="s1">&#39;:D&#39;</span><span class="p">,</span> <span class="s1">&#39;http://ah.love&#39;</span><span class="p">,</span> <span class="s1">&#39;#168cm&#39;</span><span class="p">]</span>
</code></pre></div>

<h2>2. Stemming and Lemmatisation</h2>
<p>After have every words in one sentence, we need to make sure words of different forms could be mapped into only one word. To simplify, <strong><em>play basketball</em></strong> and <strong><em>playing basketball</em></strong> should be of nearly same thing for us, but for computer, they are exactly two things.</p>
<p>In the industry, we have stemming and lemmatisation. Their differences and similarities could be concluded in mainly four aspects.</p>
<ol>
<li>They have same objectives that making word in different forms into stem, basic form of the word, but one by reducing, the other one by transforming.</li>
<li>Lemmatisation would be more difficult than stemming, considering we also have to label the part of speech for each word before transforming.</li>
<li>Stemming may not always result in a valid word, it may only give a stem. (Just part of a valid word)</li>
<li>Stemming may be used in searching more frequently, while <strong>NLP and Text-mining</strong> would be the main focus for lemmatisation.</li>
</ol>
<p>To do lemmatisation, we could directly use functions provided by nltk packages.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>

<span class="n">lemmatizer</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="s2">&quot;machines&quot;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">lemmatizer</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="s2">&quot;learning&quot;</span><span class="p">))</span>

<span class="o">&gt;&gt;</span> <span class="n">machine</span>
<span class="o">&gt;&gt;</span> <span class="n">learning</span>
</code></pre></div>

<p>We find that <strong><em>learning</em></strong> isn't been transformed, but in some cases, it should be transformed into <strong><em>learn</em></strong>, which indicates the importence to specify the part of speech. We could do this by using pos integrated in nltk.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">nltk</span>

<span class="n">sentence</span> <span class="o">=</span> <span class="s2">&quot;Apple Inc has started internal testing of several Mac models with next-generation M2 chips&quot;</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span>
<span class="n">tagged_sent</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tagged_sent</span><span class="p">)</span>

<span class="o">&gt;&gt;</span> <span class="p">[(</span><span class="s1">&#39;Apple&#39;</span><span class="p">,</span> <span class="s1">&#39;NNP&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;Inc&#39;</span><span class="p">,</span> <span class="s1">&#39;NNP&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;has&#39;</span><span class="p">,</span> <span class="s1">&#39;VBZ&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;started&#39;</span><span class="p">,</span> <span class="s1">&#39;VBN&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;internal&#39;</span><span class="p">,</span> <span class="s1">&#39;JJ&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;testing&#39;</span><span class="p">,</span> <span class="s1">&#39;NN&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;of&#39;</span><span class="p">,</span> <span class="s1">&#39;IN&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;several&#39;</span><span class="p">,</span> <span class="s1">&#39;JJ&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;Mac&#39;</span><span class="p">,</span> <span class="s1">&#39;NNP&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;models&#39;</span><span class="p">,</span> <span class="s1">&#39;NNS&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;with&#39;</span><span class="p">,</span> <span class="s1">&#39;IN&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;next-generation&#39;</span><span class="p">,</span> <span class="s1">&#39;JJ&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;M2&#39;</span><span class="p">,</span> <span class="s1">&#39;NNP&#39;</span><span class="p">),</span> <span class="p">(</span><span class="s1">&#39;chips&#39;</span><span class="p">,</span> <span class="s1">&#39;NNS&#39;</span><span class="p">)]</span>
</code></pre></div>

<p>The tags could be referenced <a href="https://www.nltk.org/book/ch05.html">here</a>, and with tags attached to each token, we could pass tags while lemmatizing token, and to unify, we also convert all characters into lower cases.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.stem</span> <span class="kn">import</span> <span class="n">WordNetLemmatizer</span>

<span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">rawContent</span><span class="p">)</span>
<span class="n">taggedTokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="n">processedTokens</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">wnl</span> <span class="o">=</span> <span class="n">WordNetLemmatizer</span><span class="p">()</span>
<span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">tag</span> <span class="ow">in</span> <span class="n">taggedTokens</span><span class="p">:</span>
    <span class="c1"># Unifiy words</span>
    <span class="n">wordPos</span> <span class="o">=</span> <span class="n">getWordPos</span><span class="p">(</span><span class="n">tag</span><span class="p">)</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">wnl</span><span class="o">.</span><span class="n">lemmatize</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="n">wordPos</span><span class="p">)</span>
</code></pre></div>

<h2>3. Stopwords</h2>
<p>When cleaning news data, using stopwords is another important step, and could significantly increase our accuracy in machine learning process. We could first take a look at stopwords nltk package provide to us, just execute the following commands in your python shell.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">nltk</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;stopwords&quot;</span><span class="p">)</span>
</code></pre></div>

<p>This is a quite simple set which definitely won't match with our use case. Basing on our data, we first calculate the words frequency and pick words that are irrelavent mannually. We would also use some techniques to reduce vocabulary size basing on word frequency.</p>
<p>After these pre-processing steps, you could save these data into any format that is convenient for you to read later on.</p>
<h1>Conclusion</h1>
<p>Here we provide a simplifed pipeline to tokenize and clean news data. It's necessary to modify some steps or add other steps based on specific scenario. Since we now have turn one sentence into tokens, we could convert these sentences into feature matrix and use for our machine learning process.</p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2022-04-12T11:12:00+08:00">Tue 12 April 2022</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/categories.html#progress-report-ref">Progress Report</a>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2022-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2022-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>